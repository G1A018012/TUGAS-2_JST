{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BinaryClassification.ipynb","provenance":[{"file_id":"1uxSMwKFo4R1StJ3rfAGJfmrRlKIQC4Yk","timestamp":1621600535719}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8Z0KV4ninwV","executionInfo":{"status":"ok","timestamp":1622013867591,"user_tz":-420,"elapsed":41073,"user":{"displayName":"putriti 18","photoUrl":"","userId":"03013429574144697971"}},"outputId":"d923a9c3-3f86-4050-d6e3-9fbca57cbbe7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e7NyqQuhj6Vw","executionInfo":{"status":"ok","timestamp":1622013874276,"user_tz":-420,"elapsed":2808,"user":{"displayName":"putriti 18","photoUrl":"","userId":"03013429574144697971"}}},"source":["# mlp for binary classification\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-kgc6fvKkGrY","executionInfo":{"status":"ok","timestamp":1622013892015,"user_tz":-420,"elapsed":911,"user":{"displayName":"putriti 18","photoUrl":"","userId":"03013429574144697971"}},"outputId":"c3907e94-80d6-433d-b735-902887a23d71"},"source":["path = '/content/drive/MyDrive/Tugas JST_2/MLP/Klasifikasi/Binary Classification/ionosphere.csv'\n","df = read_csv(path, header=None)\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","# ensure all data are floating point values\n","X = X.astype('float32')\n","# encode strings to integer\n","y = LabelEncoder().fit_transform(y)\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","# determine the number of input features\n","n_features = X_train.shape[1]\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(235, 34) (116, 34) (235,) (116,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ew827nXrzSDi","executionInfo":{"status":"ok","timestamp":1622013912347,"user_tz":-420,"elapsed":6745,"user":{"displayName":"putriti 18","photoUrl":"","userId":"03013429574144697971"}},"outputId":"a7a5f0ca-8940-481a-84fe-dc5529e92534"},"source":["# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(1, activation='sigmoid'))\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)\n","model_url = '/content/drive/MyDrive/Tugas JST_2/MLP/Klasifikasi/Binary Classification/klasifikasi_binary.h5'\n","model.save(model_url)\n","print(\"Saved\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","8/8 [==============================] - 1s 3ms/step - loss: 1.2510 - accuracy: 0.3404\n","Epoch 2/150\n","8/8 [==============================] - 0s 2ms/step - loss: 1.0800 - accuracy: 0.3362\n","Epoch 3/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.9342 - accuracy: 0.3617\n","Epoch 4/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.8101 - accuracy: 0.4085\n","Epoch 5/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.4553\n","Epoch 6/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.5872\n","Epoch 7/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.8085\n","Epoch 8/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.8383\n","Epoch 9/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.8298\n","Epoch 10/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8255\n","Epoch 11/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.8255\n","Epoch 12/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.8298\n","Epoch 13/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8340\n","Epoch 14/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8426\n","Epoch 15/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.8511\n","Epoch 16/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8553\n","Epoch 17/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8596\n","Epoch 18/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8766\n","Epoch 19/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8766\n","Epoch 20/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8809\n","Epoch 21/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8851\n","Epoch 22/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8894\n","Epoch 23/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8894\n","Epoch 24/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8936\n","Epoch 25/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8936\n","Epoch 26/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8936\n","Epoch 27/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8979\n","Epoch 28/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8979\n","Epoch 29/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8936\n","Epoch 30/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.9064\n","Epoch 31/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.9064\n","Epoch 32/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8979\n","Epoch 33/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8979\n","Epoch 34/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.9021\n","Epoch 35/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.9021\n","Epoch 36/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.9021\n","Epoch 37/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.9149\n","Epoch 38/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.9191\n","Epoch 39/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9191\n","Epoch 40/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.9191\n","Epoch 41/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9191\n","Epoch 42/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9234\n","Epoch 43/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.9277\n","Epoch 44/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9277\n","Epoch 45/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2238 - accuracy: 0.9277\n","Epoch 46/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9277\n","Epoch 47/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9277\n","Epoch 48/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9277\n","Epoch 49/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9319\n","Epoch 50/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.9319\n","Epoch 51/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.9319\n","Epoch 52/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9362\n","Epoch 53/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9319\n","Epoch 54/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9447\n","Epoch 55/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9489\n","Epoch 56/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9489\n","Epoch 57/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9532\n","Epoch 58/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9532\n","Epoch 59/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9532\n","Epoch 60/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9574\n","Epoch 61/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9617\n","Epoch 62/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9617\n","Epoch 63/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9660\n","Epoch 64/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9660\n","Epoch 65/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9702\n","Epoch 66/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9702\n","Epoch 67/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9702\n","Epoch 68/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9745\n","Epoch 69/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9745\n","Epoch 70/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9702\n","Epoch 71/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9702\n","Epoch 72/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9745\n","Epoch 73/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9787\n","Epoch 74/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.9787\n","Epoch 75/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9787\n","Epoch 76/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9787\n","Epoch 77/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9787\n","Epoch 78/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9787\n","Epoch 79/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9745\n","Epoch 80/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9787\n","Epoch 81/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9787\n","Epoch 82/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9787\n","Epoch 83/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9787\n","Epoch 84/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9787\n","Epoch 85/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9787\n","Epoch 86/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9787\n","Epoch 87/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9787\n","Epoch 88/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9787\n","Epoch 89/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9830\n","Epoch 90/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9830\n","Epoch 91/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9830\n","Epoch 92/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9872\n","Epoch 93/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9872\n","Epoch 94/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9830\n","Epoch 95/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9872\n","Epoch 96/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9915\n","Epoch 97/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9915\n","Epoch 98/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9915\n","Epoch 99/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9915\n","Epoch 100/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9915\n","Epoch 101/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9915\n","Epoch 102/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9915\n","Epoch 103/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9957\n","Epoch 104/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9915\n","Epoch 105/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9915\n","Epoch 106/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9915\n","Epoch 107/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9915\n","Epoch 108/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9915\n","Epoch 109/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9915\n","Epoch 110/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9957\n","Epoch 111/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9957\n","Epoch 112/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9957\n","Epoch 113/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9957\n","Epoch 114/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9957\n","Epoch 115/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9957\n","Epoch 116/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9957\n","Epoch 117/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9957\n","Epoch 118/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9957\n","Epoch 119/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9957\n","Epoch 120/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9957\n","Epoch 121/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9957\n","Epoch 122/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9957\n","Epoch 123/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9957\n","Epoch 124/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9957\n","Epoch 125/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9957\n","Epoch 126/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9957\n","Epoch 127/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9957\n","Epoch 128/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9957\n","Epoch 129/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9957\n","Epoch 130/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9957\n","Epoch 131/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9957\n","Epoch 132/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9957\n","Epoch 133/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9957\n","Epoch 134/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9957\n","Epoch 135/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9957\n","Epoch 136/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9957\n","Epoch 137/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9957\n","Epoch 138/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9957\n","Epoch 139/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9957\n","Epoch 140/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9957\n","Epoch 141/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9957\n","Epoch 142/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9957\n","Epoch 143/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9957\n","Epoch 144/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9957\n","Epoch 145/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9957\n","Epoch 146/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9957\n","Epoch 147/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9957\n","Epoch 148/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9957\n","Epoch 149/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9957\n","Epoch 150/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9957\n","Saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NHIJCYZqkvHJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622013919416,"user_tz":-420,"elapsed":641,"user":{"displayName":"putriti 18","photoUrl":"","userId":"03013429574144697971"}},"outputId":"04e1a205-a9c8-4284-eda9-82f67bcab8a0"},"source":["loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","print('Test Accuracy: %.3f' % acc)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Test Accuracy: 0.905\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvtHFnd40dCQ","executionInfo":{"status":"ok","timestamp":1622013989072,"user_tz":-420,"elapsed":333,"user":{"displayName":"putriti 18","photoUrl":"","userId":"03013429574144697971"}},"outputId":"c424ebdf-dd78-47bf-c722-29b996351c92"},"source":["# make a prediction\n","row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n","yhat = model.predict([row])\n","print('Predicted: %.3f' % yhat)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Predicted: 0.978\n"],"name":"stdout"}]}]}